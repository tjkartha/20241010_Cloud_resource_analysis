{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries, loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic data structure in pandas is a \"dataframe\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "Cloud_data = pd.read_csv(\"vmCloud_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list01 = [1, 7, 6, 4, 8, 24, -56, 78]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in list01:\n",
    "    print (x*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector01 = ai + bj + ck\n",
    "# 2 * vector01 = 2(ai + bj + ck)\n",
    "# 2 * vector01 = 2ai + 2bj + 2ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = pd.DataFrame(list01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data[\"cpu_usage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data[\"cpu_usage\"] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud_data = Cloud_data[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data[\"vm_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data = Cloud_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's plot some preliminary graphs to see the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data['network_traffic'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][:50], Cloud_data['cpu_usage'][:50], label='CPU Usage')\n",
    "plt.plot(Cloud_data['timestamp'][:50], Cloud_data['memory_usage'][:50], label='Memory Usage')\n",
    "plt.plot(Cloud_data['timestamp'][:50], Cloud_data['power_consumption'][:50], label='Power Consumption')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coveting col to datetime\n",
    "Cloud_data['timestamp'] = pd.to_datetime(Cloud_data['timestamp'])\n",
    "Cloud_data['hour_of_day'] = Cloud_data['timestamp'].dt.hour\n",
    "Cloud_data['day_of_week'] = Cloud_data['timestamp'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "Cloud_data['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.sort_values('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historical ussage patterns\n",
    "Cloud_data['cpu_usage_7d_avg'] = Cloud_data['cpu_usage'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "Cloud_data['memory_usage_7d_avg'] = Cloud_data['memory_usage'].rolling(window=7, min_periods=1).mean()\n",
    "\n",
    "#check\n",
    "print(Cloud_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking whether historical ussage patterns are calculated or not\n",
    "#Check for NaN Values\n",
    "print(\"NaN values in 'cpu_usage_7d_avg':\", Cloud_data['cpu_usage_7d_avg'].isnull().sum())\n",
    "print(\"NaN values in 'memory_usage_7d_avg':\", Cloud_data['memory_usage_7d_avg'].isnull().sum())\n",
    "\n",
    "# Visual Inspection\n",
    "print(\"\\nFirst few rows for visual inspection:\")\n",
    "print(Cloud_data.head())\n",
    "print(\"\\nLast few rows for visual inspection:\")\n",
    "print(Cloud_data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list01 = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list01[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CPU Usage and its 7-day rolling avg\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['cpu_usage'][::5000], label='CPU Usage')\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['cpu_usage_7d_avg'][::5000], label='7-Day Rolling Avg of CPU Usage', linestyle='--')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('CPU Usage')\n",
    "plt.title('CPU Usage and 7-Day Rolling Average')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the calculations\n",
    "\n",
    "#plotting the memory ussage and its 7-day rolling avg\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['memory_usage'][::5000], label='Memory Usage')\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['memory_usage_7d_avg'][::5000], label='7-Day Rolling Avg of Memory Usage', linestyle='--')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Memory Usage')\n",
    "plt.title('Memory Usage and 7-Day Rolling Average')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][:100000:500], Cloud_data['cpu_usage'][:100000:500], label='CPU Usage')\n",
    "plt.plot(Cloud_data['timestamp'][:100000:500], Cloud_data['memory_usage'][:100000:500], label='Memory Usage')\n",
    "plt.plot(Cloud_data['timestamp'][:100000:500], Cloud_data['power_consumption'][:100000:500], label='Power Consumption')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shall we try by changing the intervals\\?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "Cloud_data.fillna(Cloud_data.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# missing values and stuff\n",
    "for column in ['task_type', 'task_priority', 'task_status']:\n",
    "    Cloud_data[column] = Cloud_data[column].fillna(Cloud_data[column].mode()[0])\n",
    "    \n",
    "columns_to_normalize = ['cpu_usage', 'memory_usage', 'network_traffic', 'power_consumption', 'num_executed_instructions', 'execution_time', 'energy_efficiency']\n",
    "\n",
    "#using the min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "Cloud_data[columns_to_normalize] = scaler.fit_transform(Cloud_data[columns_to_normalize])\n",
    "\n",
    "#check \n",
    "print(Cloud_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][:10000:500], Cloud_data['cpu_usage'][:10000:500], label='CPU Usage')\n",
    "plt.plot(Cloud_data['timestamp'][:10000:500], Cloud_data['memory_usage'][:10000:500], label='Memory Usage')\n",
    "plt.plot(Cloud_data['timestamp'][:10000:500], Cloud_data['power_consumption'][:10000:500], label='Power Consumption')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Data Types\n",
    "print(\"\\nData types of each column:\")\n",
    "print(Cloud_data.dtypes)\n",
    "\n",
    "#Check Normalization\n",
    "print(\"\\nMin and Max values for normalized columns:\")\n",
    "for column in ['cpu_usage', 'memory_usage', 'network_traffic', 'power_consumption', 'num_executed_instructions', 'execution_time', 'energy_efficiency']:\n",
    "    print(f\"{column}: Min = {Cloud_data[column].min()}, Max = {Cloud_data[column].max()}\")\n",
    "\n",
    "#Inspection\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"\\nFirst few rows for visual inspection:\")\n",
    "print(Cloud_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing by task_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data[\"task_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_task = 'io'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data = Cloud_data[Cloud_data[\"task_type\"]==chosen_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data = Cloud_data.drop([\"task_type\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud_data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series analysis of this data can yield some results. \n",
    "1) Level: The base value for the series if it were a straight line.\n",
    "2) Trend: The linear increasing or decreasing behavior of the series over time.\n",
    "3) Seasonality: The repeating patterns or cycles of behavior over time.\n",
    "4) Noise: The variability in the observations that cannot be explained by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All-time series generally have a level, noise, while trend and seasonality are optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main features of many time series are trends and seasonal variation. Another feature of most time series is that observations close together in time tend to be correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting CPU Usage and its 7-day rolling avg\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['cpu_usage'][::5000], label='CPU Usage')\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['cpu_usage_7d_avg'][::5000], label='7-Day Rolling Avg of CPU Usage', linestyle='--')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('CPU Usage')\n",
    "plt.title('CPU Usage and 7-Day Rolling Average')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plotting the memory ussage and its 7-day rolling avg\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['memory_usage'][::5000], label='Memory Usage')\n",
    "plt.plot(Cloud_data['timestamp'][::5000], Cloud_data['memory_usage_7d_avg'][::5000], label='7-Day Rolling Avg of Memory Usage', linestyle='--')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Memory Usage')\n",
    "plt.title('Memory Usage and 7-Day Rolling Average')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test splitting and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "Cloud_data['task_priority_encoded'] = label_encoder.fit_transform(Cloud_data['task_priority'])\n",
    "Cloud_data['task_status_encoded'] = label_encoder.fit_transform(Cloud_data['task_status'])\n",
    "\n",
    "# Drop original categorical columns and 'timestamp'\n",
    "Cloud_data_processed = Cloud_data.drop(['timestamp', 'task_priority', 'task_status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (excluding target variables and 'vm_id' if it's not used as a feature)\n",
    "X = Cloud_data_processed.drop(['cpu_usage', 'memory_usage', 'network_traffic', 'vm_id'], axis=1)\n",
    "\n",
    "# Targets\n",
    "y = Cloud_data_processed[['cpu_usage', 'memory_usage', 'network_traffic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Checking the shape of the splits\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature names:\", X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a random forest regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "predictions_rf = {}\n",
    "\n",
    "# Train RandomForest model for each target\n",
    "for target in y_train.columns:\n",
    "    # RandomForest\n",
    "    model_rf = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "    model_rf.fit(X_train, y_train[target])\n",
    "    # Assuming you want to keep the RandomForest models as well, you could store them similarly to models_lgbm\n",
    "    predictions_rf[target] = model_rf.predict(X_test)\n",
    "\n",
    "# Example evaluation with RMSE for combined predictions\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "for target in y_train.columns:\n",
    "    # rmse = np.sqrt(mean_squared_error(y_test[target], y_pred_combined_df[target]))\n",
    "    rmse = np.sqrt(mean_squared_error(y_test[target], predictions_rf[target]))\n",
    "    print(f\"RMSE for {target}: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
